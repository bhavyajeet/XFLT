02/14/2023 09:03:13 PM [CRITICAL] test: merging the 12 ['as', 'bn', 'en', 'gu', 'hi', 'kn', 'ml', 'mr', 'or', 'pa', 'ta', 'te'] different languages dataset
02/14/2023 09:03:13 PM [INFO] test dataset is already present.
02/14/2023 09:03:15 PM [CRITICAL] test : script unification to Devanagari is enabled.
02/14/2023 09:03:15 PM [INFO] test dataset count : 10216
Testing: 0it [00:00, ?it/s]['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']
['Charles Henry William Sir Charlie  Robert Charl चा Dominic George Andrew Rev Francis Clar Ian Philip Vivi Carlos Lion', 'Matthew  Michael Matt Mac M Mathe Philip Mat म Sir William Mary Thomas McCa David Edward May Matth मात', 'Ital Antonio A T Sir Bornitala  Institution An É He Tark Tu Josep Tigr Tá Antar Tant Tapa', 'Hin Heid Bina Vera She Sign See Mire A And Fir  Her Kyn Vin Karim Ab Kai Bis Chris']
tensor([[0.3672, 0.3796, 0.3918, 0.3891, 0.3895, 0.1000, 0.3762, 0.4303, 0.3882,
         0.4497, 0.3834, 0.3876, 0.3541, 0.3846, 0.3363, 0.3915, 0.3615, 0.2638,
         0.3983, 0.3852],
        [0.3624, 0.1000, 0.3027, 0.4002, 0.3039, 0.2949, 0.3992, 0.2430, 0.4578,
         0.3404, 0.2977, 0.2627, 0.2783, 0.2534, 0.3387, 0.2690, 0.2894, 0.2977,
         0.3870, 0.3484],
        [0.5157, 0.3270, 0.2313, 0.2575, 0.3725, 0.3084, 0.5129, 0.1000, 0.3672,
         0.2751, 0.2788, 0.2952, 0.3407, 0.3012, 0.3452, 0.3256, 0.3269, 0.3356,
         0.3249, 0.3195],
        [0.4596, 0.3762, 0.5497, 0.2906, 0.3266, 0.3700, 0.3284, 0.4239, 0.2947,
         0.2553, 0.3372, 0.1000, 0.3620, 0.3809, 0.3494, 0.3625, 0.3441, 0.3570,
         0.3805, 0.3407]], device='cuda:0')
before us  tensor([[-2.5782e-01, -3.5239e+00, -3.6908e+00, -3.7981e+00, -4.1403e+00,
         -4.2748e+00, -4.6226e+00, -4.7267e+00, -4.7341e+00, -5.0663e+00,
         -5.1038e+00, -5.3249e+00, -6.0029e+00, -6.0131e+00, -6.0210e+00,
         -6.1167e+00, -6.3081e+00, -6.3182e+00, -6.3228e+00, -6.3755e+00],
        [-5.5660e-03, -7.1057e+00, -7.1922e+00, -7.4755e+00, -7.8529e+00,
         -8.1052e+00, -8.3741e+00, -8.7409e+00, -8.7843e+00, -8.7949e+00,
         -8.9578e+00, -9.0738e+00, -9.2763e+00, -9.5941e+00, -9.6516e+00,
         -9.7137e+00, -9.8060e+00, -9.8607e+00, -9.8848e+00, -9.9207e+00],
        [-1.6004e-02, -6.6201e+00, -6.6755e+00, -6.7727e+00, -6.8963e+00,
         -7.0088e+00, -7.5943e+00, -7.9752e+00, -8.0936e+00, -8.2855e+00,
         -8.3762e+00, -8.4855e+00, -8.6151e+00, -8.6207e+00, -8.6591e+00,
         -8.7668e+00, -8.7670e+00, -8.9011e+00, -8.9075e+00, -9.0465e+00],
        [-1.4016e-02, -5.6292e+00, -6.9059e+00, -7.6636e+00, -7.8656e+00,
         -8.0915e+00, -8.2995e+00, -8.4783e+00, -8.5743e+00, -8.6645e+00,
         -8.6907e+00, -8.7867e+00, -8.8295e+00, -9.0588e+00, -9.0709e+00,
         -9.0912e+00, -9.1149e+00, -9.1178e+00, -9.1203e+00, -9.1582e+00]],
       device='cuda:0')
ours  tensor([[-3.0010, -2.9762, -2.9517, -2.9571, -2.9564, -3.5353, -2.9828, -2.8747,
         -2.9589, -2.8360, -2.9685, -2.9601, -3.0270, -2.9660, -3.0628, -2.9522,
         -3.0122, -3.2076, -2.9387, -2.9649],
        [-2.9041, -3.4289, -3.0235, -2.8284, -3.0211, -3.0391, -2.8304, -3.1428,
         -2.7133, -2.9480, -3.0335, -3.1035, -3.0723, -3.1220, -2.9514, -3.0908,
         -3.0502, -3.0334, -2.8549, -2.9321],
        [-2.6253, -3.0028, -3.1942, -3.1417, -2.9117, -3.0399, -2.6309, -3.4567,
         -2.9223, -3.1066, -3.0991, -3.0664, -2.9753, -3.0542, -2.9663, -3.0056,
         -3.0029, -2.9856, -3.0069, -3.0178],
        [-2.7892, -2.9560, -2.6090, -3.1270, -3.0550, -2.9682, -3.0515, -2.8605,
         -3.1189, -3.1976, -3.0340, -3.5083, -2.9843, -2.9464, -3.0095, -2.9833,
         -3.0200, -2.9943, -2.9473, -3.0269]], device='cuda:0')
after us  tensor([[-2.5782e-01, -3.5239e+00, -3.6908e+00, -3.7981e+00, -4.1403e+00,
         -4.2748e+00, -4.6226e+00, -4.7267e+00, -4.7341e+00, -5.0663e+00,
         -5.1038e+00, -5.3249e+00, -6.0029e+00, -6.0131e+00, -6.0210e+00,
         -6.1167e+00, -6.3081e+00, -6.3182e+00, -6.3228e+00, -6.3755e+00],
        [-5.5660e-03, -7.1057e+00, -7.1922e+00, -7.4755e+00, -7.8529e+00,
         -8.1052e+00, -8.3741e+00, -8.7409e+00, -8.7843e+00, -8.7949e+00,
         -8.9578e+00, -9.0738e+00, -9.2763e+00, -9.5941e+00, -9.6516e+00,
         -9.7137e+00, -9.8060e+00, -9.8607e+00, -9.8848e+00, -9.9207e+00],
        [-1.6004e-02, -6.6201e+00, -6.6755e+00, -6.7727e+00, -6.8963e+00,
         -7.0088e+00, -7.5943e+00, -7.9752e+00, -8.0936e+00, -8.2855e+00,
         -8.3762e+00, -8.4855e+00, -8.6151e+00, -8.6207e+00, -8.6591e+00,
         -8.7668e+00, -8.7670e+00, -8.9011e+00, -8.9075e+00, -9.0465e+00],
        [-1.4016e-02, -5.6292e+00, -6.9059e+00, -7.6636e+00, -7.8656e+00,
         -8.0915e+00, -8.2995e+00, -8.4783e+00, -8.5743e+00, -8.6645e+00,
         -8.6907e+00, -8.7867e+00, -8.8295e+00, -9.0588e+00, -9.0709e+00,
         -9.0912e+00, -9.1149e+00, -9.1178e+00, -9.1203e+00, -9.1582e+00]],
       device='cuda:0')
['Charles', 'Henry', 'William', 'Sir', 'Charlie', 'Matthew', '', 'Michael', 'Matt', 'Mac', 'Ital', 'Antonio', 'A', 'T', 'Sir', 'Hin', 'Heid', 'Bina', 'Vera', 'She']
['Henry Edward William George Thomas James David Charles Charles Joseph John Charles Robert Anthony "  Albert Regin Andrea', 'William  David Thomas Robert Stephen Michael Peter Valentine Douglas Paul Henry Joseph George Darr Louis Edward Cli Richard K', 'o de Ital Ital Italoriano Féllangghaitalaloroiagoitoza Antoniotoriellang ato', 'aeesiasa Kaora Kao isāanazadaialaanataaramano']
tensor([[0.1000, 0.3796, 0.3787, 0.3918, 0.3834, 0.3773, 0.3877, 0.3713, 0.3672,
         0.3672, 0.4093, 0.3857, 0.3672, 0.3762, 0.3855, 0.2491, 0.1000, 0.3852,
         0.3020, 0.3741],
        [0.2627, 0.1000, 0.2690, 0.2534, 0.2810, 0.2632, 0.3027, 0.3164, 0.2958,
         0.2965, 0.2561, 0.2806, 0.2961, 0.2631, 0.3320, 0.2486, 0.2894, 0.2982,
         0.3216, 0.2888],
        [0.2791, 0.4609, 0.5157, 0.5157, 0.5157, 0.4166, 0.2952, 0.2992, 0.3213,
         0.5129, 0.4108, 0.4469, 0.5251, 0.3716, 0.3270, 0.2832, 0.3328, 0.2992,
         0.1000, 0.4600],
        [0.3635, 0.3474, 0.3566, 0.3483, 0.3489, 0.3635, 0.3994, 0.3216, 0.3994,
         0.3049, 0.3814, 0.3158, 0.4109, 0.4397, 0.3483, 0.3419, 0.3583, 0.4528,
         0.3415, 0.4033]], device='cuda:0')
before us  tensor([[ -2.3907,  -2.4469,  -2.4740,  -2.5442,  -3.0017,  -3.3783,  -3.6580,
          -4.0614,  -4.0936,  -4.1159,  -4.1838,  -4.3867,  -4.5387,  -4.6297,
          -4.9961,  -5.0408,  -5.0963,  -5.1359,  -5.2173,  -5.2623],
        [ -1.3156,  -1.6968,  -2.6244,  -3.0732,  -3.2689,  -3.3283,  -3.3434,
          -3.7427,  -4.0341,  -4.4746,  -4.4945,  -4.6366,  -4.7991,  -4.8416,
          -4.9309,  -4.9991,  -5.2438,  -5.3855,  -5.4748,  -5.5154],
        [ -0.0160,  -6.7544,  -6.9355,  -7.0944,  -7.2356,  -9.1701,  -9.3136,
          -9.5615,  -9.7699,  -9.9126, -10.1468, -10.4054, -10.5291, -10.5479,
         -10.6565, -11.0098, -11.0393, -11.1753, -11.1818, -11.2165],
        [ -0.0417,  -3.9437,  -6.0197,  -6.0370,  -6.3203,  -6.8447,  -6.9309,
          -7.4652,  -7.6854,  -7.8318,  -8.0280,  -8.1686,  -8.9398,  -9.0602,
          -9.0922,  -9.1891,  -9.3294,  -9.3563,  -9.3883,  -9.8414]],
       device='cuda:0')
ours  tensor([[-3.4931, -2.9340, -2.9357, -2.9095, -2.9262, -2.9386, -2.9178, -2.9505,
         -2.9588, -2.9588, -2.8745, -2.9217, -2.9588, -2.9406, -2.9221, -3.1949,
         -3.4931, -2.9228, -3.0891, -2.9449],
        [-3.0259, -3.3512, -3.0131, -3.0444, -2.9892, -3.0248, -2.9458, -2.9184,
         -2.9597, -2.9582, -3.0389, -2.9901, -2.9591, -3.0250, -2.8872, -3.0540,
         -2.9725, -2.9548, -2.9080, -2.9737],
        [-3.2294, -2.8659, -2.7562, -2.7562, -2.7562, -2.9545, -3.1973, -3.1892,
         -3.1450, -2.7618, -2.9660, -2.8938, -2.7375, -3.0444, -3.1337, -3.2212,
         -3.1221, -3.1892, -3.5877, -2.8677],
        [-3.0065, -3.0387, -3.0202, -3.0369, -3.0357, -3.0065, -2.9347, -3.0903,
         -2.9347, -3.1237, -2.9706, -3.1019, -2.9116, -2.8541, -3.0369, -3.0497,
         -3.0169, -2.8279, -3.0505, -2.9269]], device='cuda:0')
after us  tensor([[ -2.3907,  -2.4469,  -2.4740,  -2.5442,  -3.0017,  -3.3783,  -3.6580,
          -4.0614,  -4.0936,  -4.1159,  -4.1838,  -4.3867,  -4.5387,  -4.6297,
          -4.9961,  -5.0408,  -5.0963,  -5.1359,  -5.2173,  -5.2623],
        [ -1.3156,  -1.6968,  -2.6244,  -3.0732,  -3.2689,  -3.3283,  -3.3434,
          -3.7427,  -4.0341,  -4.4746,  -4.4945,  -4.6366,  -4.7991,  -4.8416,
          -4.9309,  -4.9991,  -5.2438,  -5.3855,  -5.4748,  -5.5154],
        [ -0.0160,  -6.7544,  -6.9355,  -7.0944,  -7.2356,  -9.1701,  -9.3136,
          -9.5615,  -9.7699,  -9.9126, -10.1468, -10.4054, -10.5291, -10.5479,
         -10.6565, -11.0098, -11.0393, -11.1753, -11.1818, -11.2165],
        [ -0.0417,  -3.9437,  -6.0197,  -6.0370,  -6.3203,  -6.8447,  -6.9309,
          -7.4652,  -7.6854,  -7.8318,  -8.0280,  -8.1686,  -8.9398,  -9.0602,
          -9.0922,  -9.1891,  -9.3294,  -9.3563,  -9.3883,  -9.8414]],
       device='cuda:0')
['Charles', 'Charles Henry', 'Charles Edward', 'Charles William', 'Charles George', 'Matthew William', 'Matthew', 'Matthew David', 'Matthew Thomas', 'Matthew Robert', 'Italo', 'Antonio de', 'Sir Ital', 'A Ital', 'T Ital', 'Hina', 'Hine', 'Hines', 'Heidi', 'Hinas']
['Town TownFrederick   Ernest WilliamHugh  Town George William WilliamAllan WilliamHoward Town "Herbert', 'KleinClaude Klein Klein KleinKennethRalph ClayFrederickStanleyRussellHerbertCorneli JadeBruce  ClaLukeHugh', 'de De Sánchez  Victoro Fél Rodrigue डी डि " दे Di Deho the do dio Zen', 'Ka Ka Kada Ka Kala Ka Kad Kaiser K Ka Tal Kash Kada Katar Kai Paw Kau Kath Kada']
/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
Traceback (most recent call last):
  File "/home/bhavyajeet.singh/msme/MEMS-XF2T/generation/mT5-baseline/main.py", line 582, in <module>
    start_training(args)
  File "/home/bhavyajeet.singh/msme/MEMS-XF2T/generation/mT5-baseline/main.py", line 428, in start_training
    trainer.test(model=model, ckpt_path=checkpoint_file)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 719, in test
    results = self.__test_given_model(model, test_dataloaders)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 784, in __test_given_model
    results = self.fit(model)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 445, in fit
    results = self.accelerator_backend.train()
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/accelerators/ddp_accelerator.py", line 148, in train
    results = self.ddp_train(process_idx=self.task_idx, model=model)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/accelerators/ddp_accelerator.py", line 282, in ddp_train
    results = self.train_or_test()
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py", line 64, in train_or_test
    results = self.trainer.run_test()
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 628, in run_test
    eval_loop_results, _ = self.run_evaluation(test_mode=True)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 579, in run_evaluation
    output = self.evaluation_loop.evaluation_step(test_mode, batch, batch_idx, dataloader_idx)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py", line 169, in evaluation_step
    output = self.trainer.accelerator_backend.test_step(args)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/accelerators/ddp_accelerator.py", line 166, in test_step
    output = self.training_step(args)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/accelerators/ddp_accelerator.py", line 158, in training_step
    output = self.trainer.model(*args)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/overrides/data_parallel.py", line 179, in forward
    output = self.module.test_step(*inputs[0], **kwargs[0])
  File "/home/bhavyajeet.singh/msme/MEMS-XF2T/generation/mT5-baseline/main.py", line 273, in test_step
    return self._step(batch, 'test')
  File "/home/bhavyajeet.singh/msme/MEMS-XF2T/generation/mT5-baseline/main.py", line 174, in _step
    return_map.update(self._generative_step(batch))
  File "/home/bhavyajeet.singh/msme/MEMS-XF2T/generation/mT5-baseline/main.py", line 136, in _generative_step
    sim_func = similarity.get_similarity,
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 26, in decorate_context
    return func(*args, **kwargs)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/transformers/generation_utils.py", line 1140, in generate
    **model_kwargs,
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/transformers/generation_utils.py", line 1933, in beam_search
    sim_tok = sim_func(tokens, inp_str, F.cosine_similarity).mean()
  File "/home/bhavyajeet.singh/msme/MEMS-XF2T/generation/mT5-baseline/similarity.py", line 36, in get_similarity
    fact_embedding = get_embedding(" ".join(facts))[1:-1]
  File "/home/bhavyajeet.singh/msme/MEMS-XF2T/generation/mT5-baseline/similarity.py", line 22, in get_embedding
    states = model(**tokenized_facts).hidden_states
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 1001, in forward
    return_dict=return_dict,
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 589, in forward
    output_attentions,
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 475, in forward
    past_key_value=self_attn_past_key_value,
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 408, in forward
    output_attentions,
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py", line 329, in forward
    attention_probs = nn.Softmax(dim=-1)(attention_scores)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/torch/nn/modules/activation.py", line 1198, in forward
    return F.softmax(input, self.dim, _stacklevel=5)
  File "/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/torch/nn/functional.py", line 1512, in softmax
    ret = input.softmax(dim)
KeyboardInterrupt