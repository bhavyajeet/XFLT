09/14/2022 04:24:06 AM [CRITICAL] val: merging the 2 ['en', 'hi'] different languages dataset
09/14/2022 04:24:06 AM [INFO] val dataset is already present.
09/14/2022 04:24:06 AM [INFO] val dataset count : 18918
Validation sanity check:  50%|████████████████████████                        | 1/2 [00:00<00:00,  5.96it/s]09/14/2022 04:24:07 AM [INFO] epoch : 0 - average_val_loss : 24.337757
09/14/2022 04:24:07 AM [CRITICAL] train: merging the 2 ['en', 'hi'] different languages dataset
09/14/2022 04:24:07 AM [INFO] train dataset is already present.
  | Name  | Type                        | Params
------------------------------------------------------
0 | model | MT5ForConditionalGeneration | 300 M
/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
09/14/2022 04:24:07 AM [INFO] train dataset count : 18918
Epoch 0:   0%|                                    | 2/3548 [00:01<34:06,  1.73it/s, loss=25.664, v_num=ll6k]
/home/bhavyajeet.singh/anaconda3/envs/xalign/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.

































































































































































































































































































































































































































































































































































































































































Epoch 0:  68%|███████████████████████           | 2401/3548 [21:28<10:15,  1.86it/s, loss=0.946, v_num=ll6k]






















Validating:  99%|██████████████████████████████████████████████████████▍| 1170/1183 [00:45<00:00, 26.53it/s]
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 2364 < 3552; dropping {'avg_val_loss': 0.7578041553497314, 'epoch': 0}.

Validating: 100%|██████████████████████████████████████████████████████▉| 1182/1183 [00:45<00:00, 26.28it/s]
Epoch 0: 100%|██████████████| 3548/3548 [22:17<00:00,  2.65it/s, loss=0.946, v_num=ll6k, avg_val_loss=0.758]09/14/2022 04:46:25 AM [INFO] epoch : 0 - average_train_loss : 2.043646

































































































































































































































































































































































































































































































































































































































































Epoch 1:  67%|▋| 2376/3548 [21:28<10:35,  1.84it/s, loss=0.717, v_num=ll6k, avg_v























Validating: 100%|███████████████████████████▉| 1182/1183 [00:45<00:00, 26.29it/s]
[34m[1mwandb[39m[22m: [33mWARNING[39m Step must only increase in log calls.  Step 4729 < 7102; dropping {'avg_val_loss': 0.5399231910705566, 'epoch': 1}.
Epoch 1: 100%|█| 3548/3548 [22:18<00:00,  2.65it/s, loss=0.717, v_num=ll6k, avg_v09/14/2022 05:08:44 AM [INFO] epoch : 1 - average_train_loss : 0.901406
Epoch 2:   0%| | 1/3548 [00:00<32:45,  1.80it/s, loss=0.740, v_num=ll6k, avg_val_





































































