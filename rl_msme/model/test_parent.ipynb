{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import functorch\n",
    "import regex as re \n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from functools import lru_cache\n",
    "from nltk.util import ngrams \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_duplicates(embeddings, lst, mean=True):\n",
    "    embeddings = torch.cat([e.reshape(1, -1) for i, e in enumerate(embeddings) if lst[i]!=None], dim=0)\n",
    "    lst = [i for i in lst if i!=None]\n",
    "    output = [None for _ in range(len(set(lst)))]\n",
    "    i = 0\n",
    "    for idx, i in enumerate(lst):\n",
    "        if(i!=None):\n",
    "            if(output[i] == None):\n",
    "                output[i] = embeddings[idx, :].reshape(1, -1)\n",
    "            else:\n",
    "                output[i] = torch.cat((output[i], embeddings[idx, :].reshape(1, -1)), dim=0)\n",
    "    if(mean):\n",
    "        for idx, val in enumerate(output):\n",
    "            output[idx] = torch.mean(output[idx], dim=0).reshape(1, -1)\n",
    "    return output\n",
    "\n",
    "def get_facts(source, token_split=True):\n",
    "    words = source.split(\":\")[1].split(\" \")\n",
    "    facts = re.split(r'<[^>]*>', \" \".join(words))\n",
    "    facts = [re.sub(r'_', ' ', facts[i].strip()) for i in range(len(facts))]\n",
    "    if(token_split):\n",
    "        return tuple([re.sub(r'_', ' ', f) for i in range(len(facts)) for f in facts[i].split()]), [i-1 for i, word in enumerate(facts) for _ in range(len(word.split()))]\n",
    "    return tuple(facts), []\n",
    "\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_embedding(tokens, model, tokenizer, split_into_words=False, parent_device = 'cuda:4'):\n",
    "    with torch.no_grad():\n",
    "        tokenized_facts = tokenizer(tokens, padding=True, truncation=True, max_length=512, is_split_into_words=split_into_words, return_tensors=\"pt\").to(parent_device)\n",
    "        #print(tokenizer.decode(tokenized_facts[1].ids))\n",
    "        batch_states = model(**tokenized_facts).hidden_states\n",
    "        batch_output = torch.stack([batch_states[i] for i in range(len(batch_states))])\n",
    "        batch_output = batch_output.squeeze()\n",
    "        batch_final_hidden_state = torch.mean(batch_output[:, :, ...], dim=0)\n",
    "        return batch_final_hidden_state[:, 1:-1, :], list(map(lambda i: tokenized_facts.word_ids(i)[1:-1], range(len(tokens))))\n",
    "\n",
    "def entailment_prob(fact_embeddings, generated_ngram, threshold=None): \n",
    "    if(generated_ngram.dim() == 1):\n",
    "        generated_ngram = generated_ngram.reshape(1, -1)\n",
    "    similarities = functorch.vmap(lambda row_a: F.cosine_similarity(row_a, fact_embeddings))(generated_ngram)\n",
    "    if(threshold):\n",
    "        #print(torch.max(similarities, dim=1).values.cpu())\n",
    "        return np.mean((torch.max(similarities, dim=1).values > threshold).int().cpu().numpy())\n",
    "    return np.mean(torch.max(similarities, dim=1).values.cpu().numpy())\n",
    "\n",
    "def get_coverage_reward(generated, source,  model, parentTokenizer, parent_device):\n",
    "    generated = list(map(lambda gen: re.sub(r\"[',.ред()]\", '', gen), generated))\n",
    "    generated_tokens = tuple(map(lambda gen: tuple(re.sub(r'[ ]{2,}', ' ', gen.strip()).split()),  generated))\n",
    "    generated_embeddings, g_idx = get_embedding(generated_tokens, model, parentTokenizer, split_into_words=True, parent_device=parent_device)\n",
    "    gen_emb = list(map(lambda ge, gi: group_duplicates(ge, gi), generated_embeddings, g_idx))\n",
    "    # gen_emb = [] \n",
    "    # for ge, gi in zip(generated_embeddings, g_idx):\n",
    "    #     gen_emb.append(group_duplicates(ge, gi))\n",
    "\n",
    "    fact_pos_pairs = tuple(map(lambda src: get_facts(src, token_split=True), source))\n",
    "    facts = tuple(fact_pos_pairs[i][0] for i in range(len(fact_pos_pairs)))\n",
    "    #print(facts)\n",
    "    fact_pos = tuple(fact_pos_pairs[i][1] for i in range(len(fact_pos_pairs)))\n",
    "    fact_embeddings, f_idx = get_embedding(facts, model, parentTokenizer, split_into_words=True, parent_device=parent_device)\n",
    "    #print(fact_embeddings[0].shape)\n",
    "    #print(f_idx[0])\n",
    "    fact_embeddings = list(map(lambda fe, fi: group_duplicates(fe, fi), fact_embeddings, f_idx))\n",
    "    fact_emb = [torch.cat(fe).squeeze() for fe in fact_embeddings]\n",
    "    batch_eps = []\n",
    "    for generated_tokens_, gen_emb_, fact_emb_ in zip(generated_tokens, gen_emb, fact_emb):\n",
    "        g_dict = {t: emb for t, emb in zip(generated_tokens_, gen_emb_)}\n",
    "        generated_ngrams = Counter(list(ngrams(generated_tokens_, 1)))\n",
    "        eps = [] \n",
    "        for ngram, count in generated_ngrams.items():\n",
    "            ngram_embedding = torch.cat([g_dict[i] for i in ngram if i in g_dict]).squeeze()\n",
    "            ep = entailment_prob(fact_emb_, ngram_embedding, 0.4)\n",
    "            eps.append(ep)\n",
    "        batch_eps.append(np.mean(eps))\n",
    "    return batch_eps\n",
    "\n",
    "# def get_coverage_reward(generated, source, model, parentTokenizer, parent_device):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4804,  0.0539,  0.0544,  ..., -0.3140,  0.1942,  0.1003],\n",
       "          [ 0.2996, -0.0531,  0.0894,  ...,  0.0893,  0.2084, -0.0393],\n",
       "          [-0.2180,  0.1041, -0.0069,  ...,  0.0867,  0.0623, -0.1641],\n",
       "          [-0.6242, -0.0263, -0.1341,  ...,  0.2337, -0.1200,  0.0210],\n",
       "          [-0.3984,  0.0523, -0.0879,  ...,  0.0384, -0.0524, -0.0337]],\n",
       " \n",
       "         [[-0.4739,  0.0522,  0.0419,  ..., -0.3060,  0.1482,  0.1512],\n",
       "          [ 0.3545, -0.0529,  0.1093,  ...,  0.0431,  0.1868, -0.0357],\n",
       "          [-0.1713,  0.1216,  0.0378,  ...,  0.0866,  0.0663, -0.1286],\n",
       "          [-0.7763,  0.0850, -0.0959,  ...,  0.1394, -0.1650, -0.0215],\n",
       "          [-0.4028,  0.0396, -0.0659,  ...,  0.0565, -0.0691, -0.0366]]],\n",
       "        device='cuda:0'),\n",
       " [[0, 1, 2, 3, 4], [0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embedding(tuple(('this is the first sentence', 'this is the second sentence')), parentModel, parentTok, False, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(197285, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parentModel =  AutoModel.from_pretrained(\"google/muril-base-cased\", output_hidden_states=True).to('cuda')\n",
    "parentTok =  AutoTokenizer.from_pretrained(\"google/muril-base-cased\", padding='max_length', truncation='max_length', max_length=512)\n",
    "parentModel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6666666666666666, 0.47058823529411764]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coverage_reward(gen, src, parentModel, parentTok, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = ['generate english high : <H> charlie townsend <R> date_of_birth <T> 07 november 1876 <R> date_of_death <T> 17 october 1958 <R> occupation <T> cricketer', 'generate english high : <H> matthew kleinveldt <R> country_of_citizenship <T> united kingdom <R> date_of_birth <T> 10 august 1989 <R> occupation <T> cricketer']\n",
    "gen = ['Charles Henry Dunsend ( 7 November 1876 - 17 October 1958 ) was an English first-class cricketer.', 'Matthew William Kleinveldt ( born 10 August 1989 ) is an English cricketer who plays for Lancashire and England.' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Charles Henry Dunsend 7 November 1876 - 17 October 1958 was an English first-class cricketer', 'Matthew William Kleinveldt born 10 August 1989 is an English cricketer who plays for Lancashire and England')\n",
      "tensor([[[ 0.0835,  0.0800, -0.0204,  ...,  0.1786,  0.2951, -0.0416],\n",
      "         [ 0.3666, -0.1116,  0.1555,  ...,  0.0649,  0.2151, -0.0020],\n",
      "         [-0.4001,  0.0111, -0.1273,  ..., -0.0014,  0.0995,  0.0403],\n",
      "         ...,\n",
      "         [-0.0201, -0.0308,  0.0537,  ..., -0.1912, -0.2950,  0.0696],\n",
      "         [-0.2440,  0.1058, -0.0462,  ...,  0.1693,  0.0591, -0.0303],\n",
      "         [-0.3973,  0.0672,  0.0983,  ..., -0.2901, -0.1923, -0.0645]],\n",
      "\n",
      "        [[ 0.1944,  0.0336, -0.1154,  ...,  0.2096,  0.1232,  0.0467],\n",
      "         [ 0.0797, -0.0440,  0.1365,  ...,  0.2682,  0.1908,  0.0426],\n",
      "         [ 0.0481,  0.0775,  0.0491,  ...,  0.0195,  0.0543,  0.0102],\n",
      "         ...,\n",
      "         [-0.6054, -0.0656,  0.0046,  ..., -0.1141,  0.0216,  0.0881],\n",
      "         [ 0.0234,  0.0373,  0.1339,  ...,  0.0184, -0.1576,  0.1697],\n",
      "         [-0.5103, -0.1258,  0.0480,  ...,  0.3621,  0.0147, -0.0668]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "<lambda>() missing 1 required positional argument: 'gi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_coverage_reward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparentModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparentTok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 48\u001b[0m, in \u001b[0;36mget_coverage_reward\u001b[0;34m(generated, source, model, parentTokenizer, parent_device)\u001b[0m\n\u001b[1;32m     46\u001b[0m generated_embeddings, g_idx \u001b[38;5;241m=\u001b[39m get_embedding(generated_tokens, model, parentTokenizer, \u001b[38;5;28;01mFalse\u001b[39;00m, parent_device)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_embeddings)\n\u001b[0;32m---> 48\u001b[0m gen_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_duplicates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenerated_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m facts, fact_pos \u001b[38;5;241m=\u001b[39m get_facts(source, token_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     51\u001b[0m fact_embeddings, f_idx \u001b[38;5;241m=\u001b[39m get_embedding(\u001b[38;5;28mtuple\u001b[39m(facts), model, parentTokenizer, split_into_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parent_device\u001b[38;5;241m=\u001b[39mparent_device)\n",
      "\u001b[0;31mTypeError\u001b[0m: <lambda>() missing 1 required positional argument: 'gi'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_coverage_reward(gen[0], src[0], parentModel, parentTok, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('textbox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84fc63c8ae42b05f54f8c8e4c73411ce0404f059987aac7c448c556c45688d5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
