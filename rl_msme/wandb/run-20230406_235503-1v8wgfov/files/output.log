
[38mic| model_gpus: [1]
[38mic| next(model.parameters()).is_cuda: True
[38mic| start_epoch: 0, final_checkpoint: None
  0%|                                                                                                                                                    | 0/5 [00:00<?, ?it/s, loss=1]
[38m                           [     0, 250099,      1]], device='cuda:1')[39m                                                                       | 0/33932 [00:00<?, ?it/s, model_number=1]
[38m    greedy_idx: tensor([[250099, 250099, 178829,      1,      1,      1,      1,  11267,      1,
[38m                              1,      1, 250068, 250069,      1,      1, 250069, 250068, 250069,
[38m                              1,      1,    392,      1, 250069,      1,      1,      1,      1,
[38m                              1,      1,      1, 188891,      1, 250068,      1,      1,      1,
[38m                              1, 250068,      1,      1, 250068,      1, 250068, 250068,      1,
[38m                              1,      1, 250068, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099],
[38m                        [250099, 160430, 250044, 250068, 250068,      1, 250044, 250095,    259,
[38m                              1, 250093,      1,      1,   8117,      1,      1,      1, 250068,
[38m                         250068, 225621, 250068, 250088, 250095,      1,      1,      1, 250046,
[38m                         250098,      1,      1, 250068, 250068,      1, 250068,      1,      1,
[38m                              1, 250059, 250068,    259,  87164,      1, 250045,      1,      1,
[38m                              1,      1, 250084, 250045,    259,      1,   1104,    259, 250059,
[38m                              1,      1,    259,      1,  92883, 250092,      1]],
[38m                       device='cuda:1')
                                                                                                                                                                                       [38mic| generated_ids: tensor([[     0, 250099,      1],
[38m                           [     0, 250099,      1]], device='cuda:1')[39m                                                            | 1/33932 [00:01<13:33:54,  1.44s/it, model_number=1]
[38m    greedy_idx: tensor([[250099,    259,      1,    290,      1,  27675, 250048,    483,      1,
[38m                              1,      1,      1,      1,      1,      1, 250048,    259,      1,
[38m                         250051,    268,    278,      1, 250096, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099],
[38m                        [250099, 250099,      1,    275,      1,      1,      1,      1,    302,
[38m                              1,      1,      1,      1, 129338,      1,      1,      1,      1,
[38m                          40137,      1,    259,    259,      1,      1,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,    290,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1,      1,
[38m                         250088, 250088,      1]], device='cuda:1')
                                                                                                                                                                                       [38mic| generated_ids: tensor([[     0, 250099,      1],
[38m                           [     0, 250099,      1]], device='cuda:1')[39m                                                            | 2/33932 [00:01<10:16:46,  1.09s/it, model_number=1]
[38m    greedy_idx: tensor([[250099,    259,    277,      1,      1,    259,      1, 250089,      1,
[38m                           1042,      1,      1,      1,   1042,    270,    285,    261,      1,
[38m                            261,    261,      1,    259,    262, 250063, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099,
[38m                         250099, 250099, 250099, 250099, 250099, 250099, 250099, 250099],
[38m                        [250099, 250099,    302, 250065,      1,      1,      1,      1,      1,
[38m                          60799,      1, 250071,      1,    261,      1,      1, 250043,    259,
[38m                              1,      1,      1,      1,      1,      1,    271,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1,      1,
[38m                              1,      1,      1,      1,      1,      1,      1,      1]],
[38m                       device='cuda:1')
                                                                                                                                                                                       Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f832d0b13b0>
Traceback (most recent call last):                                                                                                 | 3/33932 [00:01<7:52:29,  1.20it/s, model_number=1]
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1466, in __del__
    self._shutdown_workers()
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1430, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/multiprocessing/process.py", line 140, in join
    res = self._popen.wait(timeout)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/multiprocessing/popen_fork.py", line 45, in wait
    if not wait([self.sentinel], timeout):
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/multiprocessing/connection.py", line 921, in wait
    ready = selector.select(timeout)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt:
  0%|                                                                                                                              | 3/33932 [00:02<6:42:00,  1.41it/s, model_number=1]
  0%|                                                                                                                                                    | 0/5 [00:02<?, ?it/s, loss=1]
Traceback (most recent call last):
  File "train_ddp.py", line 422, in <module>
    main()
  File "train_ddp.py", line 332, in main
    middle_output = model.module.middle(batch)
  File "/home2/aditya_hari/multisent/MEMS-XF2T/rl_msme/model/model_ddp.py", line 87, in middle
    max_length=self.tgt_max_seq_len
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/generation/utils.py", line 1415, in generate
    **model_kwargs,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/generation/utils.py", line 2205, in greedy_search
    output_hidden_states=output_hidden_states,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 1748, in forward
    return_dict=return_dict,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 1056, in forward
    output_attentions=output_attentions,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 563, in forward
    output_attentions=output_attentions,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 468, in forward
    output_attentions=output_attentions,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 386, in forward
    hidden_states, self.v, key_value_states, past_key_value[1] if past_key_value is not None else None
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 366, in project
    hidden_states = torch.cat([past_key_value, hidden_states], dim=2)
KeyboardInterrupt