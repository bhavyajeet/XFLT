
[38mic| model_gpus: [1]
[38mic| next(model.parameters()).is_cuda: True
[38mic| start_epoch: 0, final_checkpoint: None
  0%|                                                                                                                                                    | 0/5 [00:00<?, ?it/s, loss=1]
[38m    greedy_idx.shape: torch.Size([2, 61])[39m                                                                                                    | 0/33932 [00:00<?, ?it/s, model_number=1]
[38mic| self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True): ['<extra_id_0>', '<extra_id_0>']
[38mic| self.tokenizer.batch_decode(greedy_idx, skip_special_tokens=True): ['<extra_id_0> <extra_id_0>–º—ç—ÄÎãàÎã§ <extra_id_31> <extra_id_30> <extra_id_30> '
[38m                                                                        '<extra_id_31> <extra_id_30> 2018 <extra_id_30>„Éê„ÉÉ„Éà <extra_id_31> '
[38m                                                                        '<extra_id_31> <extra_id_31> <extra_id_31> <extra_id_31> <extra_id_31> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0>',
[38m                                                                        '<extra_id_0>—É–ª—å—Ç <extra_id_55> <extra_id_31> <extra_id_31> <extra_id_55> '
[38m                                                                        '<extra_id_4>  <extra_id_6>Ÿàÿ≤ <extra_id_31> <extra_id_31>Âõ∞„Çä <extra_id_31> '
[38m                                                                        '<extra_id_11> <extra_id_4> <extra_id_53> <extra_id_1> <extra_id_31> '
[38m                                                                        '<extra_id_31> <extra_id_31> <extra_id_40> <extra_id_31> Cricket '
[38m                                                                        '<extra_id_54> <extra_id_15> <extra_id_54> –∏–º  <extra_id_40> eries '
[38m                                                                        '<extra_id_7>']
                                                                                                                                                                                       [38mic| generated_ids.shape: torch.Size([2, 3])
[38m    greedy_idx.shape: torch.Size([2, 147])[39m                                                                                        | 1/33932 [00:01<15:35:57,  1.66s/it, model_number=1]
[38mic| self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True): ['<extra_id_0>', '<extra_id_0>']
[38mic| self.tokenizer.batch_decode(greedy_idx, skip_special_tokens=True): ['<extra_id_0> _players <extra_id_51>). <extra_id_51>  <extra_id_48>oen '
[38m                                                                        '<extra_id_3> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0>',
[38m                                                                        '<extra_id_0> <extra_id_0>/...œÑœÑanimation  _ <extra_id_11> <extra_id_11>']
                                                                                                                                                                                       [38mic| generated_ids.shape: torch.Size([2, 3])
[38m    greedy_idx.shape: torch.Size([2, 53])[39m                                                                                         | 2/33932 [00:01<11:33:27,  1.23s/it, model_number=1]
[38mic| self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True): ['<extra_id_0>', '<extra_id_0>']
[38mic| self.tokenizer.batch_decode(greedy_idx, skip_special_tokens=True): ["<extra_id_0>' <extra_id_10> < <td,,, a <extra_id_36> <extra_id_0> "
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0>',
[38m                                                                        '<extra_id_0> <extra_id_0>... <extra_id_34>‡§∞‡§≤ <extra_id_28>, <extra_id_56> )']
                                                                                                                                                                                       [38mic| generated_ids.shape: torch.Size([2, 67])
[38m    greedy_idx.shape: torch.Size([2, 98])[39m                                                                                          | 3/33932 [00:02<8:41:44,  1.08it/s, model_number=1]
[38mic| self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True): ['<extra_id_0>',
[38m                                                                           '<extra_id_0> <H> mohammed salim <H> mohammed salim <H> mohammed salim <H> '
[38m                                                                           'mohammed salim <H> mohammed salim <H> mohammed salim <H> mohammed salim <H> '
[38m                                                                           'mohammed salim']
[38mic| self.tokenizer.batch_decode(greedy_idx, skip_special_tokens=True): ['<extra_id_0>>  ...,,) <extra_id_8>.   <extra_id_12>e <extra_id_8>pfung) '
[38m                                                                        '<extra_id_26>—â   licitud t¬∞H <extra_id_16> H—è ¬∞   < < <extra_id_56> )  )   '
[38m                                                                        ') ',
[38m                                                                        '<extra_id_0>th <extra_id_19>  –ª–æ–≤–Ω–∞ <extra_id_8>Election gaur     ))     3–±  '
[38m                                                                        '<extra_id_11>  (  –í    –í  ,   —á–∫–µ  –ö  –§  Î°Ø   - ¬´ <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0>']
                                                                                                                                                                                       Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f12d9c4c3b0>
Traceback (most recent call last):                                                                                                 | 4/33932 [00:03<8:57:37,  1.05it/s, model_number=1]
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1466, in __del__
    self._shutdown_workers()
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1430, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/multiprocessing/process.py", line 140, in join
    res = self._popen.wait(timeout)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/multiprocessing/popen_fork.py", line 45, in wait
    if not wait([self.sentinel], timeout):
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/multiprocessing/connection.py", line 921, in wait
    ready = selector.select(timeout)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt:
  0%|                                                                                                                              | 4/33932 [00:03<7:36:17,  1.24it/s, model_number=1]
  0%|                                                                                                                                                    | 0/5 [00:03<?, ?it/s, loss=1]
Traceback (most recent call last):
  File "train_ddp.py", line 422, in <module>
    main()
  File "train_ddp.py", line 332, in main
    middle_output = model.module.middle(batch)
  File "/home2/aditya_hari/multisent/MEMS-XF2T/rl_msme/model/model_ddp.py", line 89, in middle
    outputs = self(batch)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/multisent/MEMS-XF2T/rl_msme/model/model_ddp.py", line 63, in forward
    outputs = self.model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 1748, in forward
    return_dict=return_dict,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 1056, in forward
    output_attentions=output_attentions,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 563, in forward
    output_attentions=output_attentions,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 468, in forward
    output_attentions=output_attentions,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 431, in forward
    attn_output = unshape(torch.matmul(attn_weights, value_states))  # (batch_size, seq_length, dim)
KeyboardInterrupt