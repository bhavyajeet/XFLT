
[38mic| model_gpus: [0]
[38mic| next(model.parameters()).is_cuda: True
[38mic| start_epoch: 0, final_checkpoint: None
  0%|                                                                                                                                                                   | 0/5 [00:00<?, ?it/s, loss=0]

[38mic| f"Model number {local_rank} saving": 'Model number 0 saving'[39m                                                                                  | 9/33932 [00:03<2:30:34,  3.75it/s, model_number=0]
 20%|███████████████████████████████                                                                                                                            | 1/5 [00:07<00:28,  7.02s/it, loss=0]

[38mic| f"Model number {local_rank} saving": 'Model number 0 saving'[39m                                                                                  | 9/33932 [00:02<2:02:28,  4.62it/s, model_number=0]
 40%|██████████████████████████████████████████████████████████████                                                                                             | 2/5 [00:12<00:20,  6.67s/it, loss=0]

[38mic| f"Model number {local_rank} saving": 'Model number 0 saving'[39m                                                                                  | 9/33932 [00:02<1:56:41,  4.85it/s, model_number=0]
  0%|▏                                                                                                                                                               | 9/6771 [00:01<19:25,  5.80it/s]
 60%|█████████████████████████████████████████████████████████████████████████████████████████████                                                              | 3/5 [00:18<00:12,  6.44s/it, loss=0]


[38mic| f"Model number {local_rank} saving": 'Model number 0 saving'[39m                                                                                  | 9/33932 [00:02<2:10:20,  4.34it/s, model_number=0]
  0%|▏                                                                                                                                                               | 9/6771 [00:01<21:23,  5.27it/s]
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 4/5 [00:24<00:06,  6.32s/it, loss=0]
Traceback (most recent call last):                                                                                                                          | 0/33932 [00:00<?, ?it/s, model_number=0]
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1466, in __del__
    self._shutdown_workers()
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1430, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/multiprocessing/process.py", line 140, in join
    res = self._popen.wait(timeout)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/multiprocessing/popen_fork.py", line 45, in wait
    if not wait([self.sentinel], timeout):
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/multiprocessing/connection.py", line 921, in wait
    ready = selector.select(timeout)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt:
  0%|                                                                                                                                                       | 0/33932 [00:01<?, ?it/s, model_number=0]
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 4/5 [00:26<00:06,  6.53s/it, loss=0]
Traceback (most recent call last):
  File "train_ddp.py", line 414, in <module>
    main()
  File "train_ddp.py", line 328, in main
    middle_output = model.module.middle(batch)
  File "/home2/aditya_hari/multisent/MEMS-XF2T/rl_msme/model/model_ddp.py", line 86, in middle
    max_length=self.tgt_max_seq_len
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/generation/utils.py", line 1415, in generate
    **model_kwargs,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/generation/utils.py", line 2205, in greedy_search
    output_hidden_states=output_hidden_states,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 1748, in forward
    return_dict=return_dict,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 1056, in forward
    output_attentions=output_attentions,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 591, in forward
    output_attentions=output_attentions,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 505, in forward
    output_attentions=output_attentions,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 434, in forward
    present_key_value_state = (key_states, value_states) if (self.is_decoder and use_cache) else None
KeyboardInterrupt