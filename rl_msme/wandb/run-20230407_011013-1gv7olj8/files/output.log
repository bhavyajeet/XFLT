
[38mic| model_gpus: [0]
[38mic| next(model.parameters()).is_cuda: True
[38mic| start_epoch: 0, final_checkpoint: None
  0%|                                                                                                                                                    | 0/5 [00:00<?, ?it/s, loss=0]

[38m    greedy_idx.shape: torch.Size([2, 41])[39m                                                                                                    | 0/33932 [00:00<?, ?it/s, model_number=0]
[38mic| self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True): ['à¤¤à¤¾à¤° à¤‰à¤²à¥à¤²à¥‡à¤–à¤¯à¥‹à¤—à¥à¤¯ à¤°à¤šà¤¨à¤¾à¤—à¥à¤²à¥‹ à¤¹à¤² " à¤¦à¥à¤¯ à¤°à¥€à¤® à¤…à¤¬ à¤¦à¥à¤¯ à¤…à¥à¤¯à¤¾à¤¨à¥à¤Ÿà¤¿à¤¨à¥‹à¤ªà¤¿à¤†, à¤¬à¤¾à¤¯à¤¼à¥‹à¤—à¥à¤°à¤¾à¤«à¤¿à¤† '
[38m                                                                           'à¤²à¤°à¤¿à¤¯à¤¼à¥‡à¤Ÿà¤°à¥€ ", " à¤¦à¥à¤¯ à¤°à¥€à¤® à¤…à¤¬ à¤¦à¥à¤¯ à¤…à¥à¤¯à¤¾à¤¨à¥à¤Ÿà¤¿à¤¨à¥‹à¤ªà¤¿à¤†, à¤•à¥à¤¬à¤²à¤¾ à¤–à¤¾à¤¨ ", " à¤¦à¥à¤¯ à¤°à¥€à¤® à¤…à¤¬ à¤¦à¥à¤¯ '
[38m                                                                           'à¤…à¥à¤¯à¤¾à¤¨à¥à¤Ÿà¤¿à¤¨à¥‹à¤ªà¤¿à¤†, à¤¦à¥à¤¯ à¤°à¥€à¤® à¤…à¤¬ à¤¦à¥à¤¯ à¤…à¥à¤¯à¤¾à¤¨à¥à¤Ÿà¤¿à¤¨à¥‹à¤ªà¤¿à¤†, à¤¦à¥à¤¯ à¤°à¥€à¤® à¤…à¤¬ à¤¦à¥à¤¯ à¤…à¥à¤¯à¤¾à¤¨à¥à¤Ÿà¤¿à¤¨à¥‹à¤ªà¤¿à¤†, '
[38m                                                                           'à¤¦à¥à¤¯ à¤°à¥€à¤® à¤…à¤¬ à¤¦à¥à¤¯ à¤…à¥à¤¯à¤¾à¤¨à¥à¤Ÿà¤¿à¤¨à¥‹à¤ªà¤¿à¤†, à¤¦à¥à¤¯ à¤°à¥€à¤® à¤…à¤¬ à¤¦à¥à¤¯ à¤…à¥à¤¯à¤¾à¤¨à¥à¤Ÿà¤¿à¤¨à¥‹à¤ªà¤¿à¤†, à¤¦à¥à¤¯ à¤°à¥€à¤® à¤…à¤¬ à¤¦à¥à¤¯ '
[38m                                                                           'à¤…à¥à¤¯à¤¾à¤¨à¥à¤Ÿà¤¿à¤¨à¥‹à¤ªà¤¿à¤†, à¤¦à¥à¤¯ à¤°à¥€à¤® à¤…à¤¬ à¤¦à¥à¤¯ à¤…à¥à¤¯à¤¾à¤¨à¥à¤Ÿà¤¿à¤¨à¥‹à¤ªà¤¿à¤†, à¤¬à¤¾à¤¯à¤¼à¥‹à¤—à¥à¤°à¤¾à¤«à¤¿à¤† à¤²à¤°à¤¿à¤¯à¤¼à¥‡à¤Ÿà¤°à¥€à¤†, à¤¦à¥à¤¯ '
[38m                                                                           'à¤°à¥€à¤® à¤…à¤¬ à¤¦à¥à¤¯ à¤…à¥à¤¯à¤¾à¤¨à¥à¤Ÿà¤¿à¤¨à¥‹à¤ªà¤¿à¤†, à¤¦à¥à¤¯ à¤°à¥€à¤® à¤…à¤¬ à¤¦à¥à¤¯ à¤…à¥à¤¯à¤¾à¤¨à¥à¤Ÿà¤¿à¤¨à¥‹',
[38m                                                                           'à¤¸à¥à¤¨à¥€à¤² à¤µà¤°à¥à¤®à¤¾ ( à¤œà¤¨à¥à¤® 28 à¤«à¥‡à¤¬à¥à¤°à¥à¤¯à¤¼à¤¾à¤°à¤¿ 1974 ), à¤¸à¥à¤¨à¥€à¤² à¤µà¤°à¥à¤®à¤¾ à¤¨à¤¾à¤®à¥‡ à¤…à¤§à¤¿à¤• à¤ªà¤°à¤¿à¤šà¤¿à¤¤, à¤à¤• '
[38m                                                                           'à¤­à¤¾à¤°à¤¤à¥€à¤¯à¤¼ à¤…à¤­à¤¿à¤¨à¥‡à¤¤à¤¾, à¤¯à¤¿à¤¨à¤¿ à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¤¾à¤®à¤¿à¤², à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¤¾à¤®à¤¿à¤², à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, '
[38m                                                                           'à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¤¾à¤®à¤¿à¤², à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¤¾à¤®à¤¿à¤², à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, '
[38m                                                                           'à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¤¾à¤®à¤¿à¤², à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, '
[38m                                                                           'à¤¤à¤¾à¤®à¤¿à¤², à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¤¾à¤®à¤¿à¤², à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥, '
[38m                                                                           'à¤¤à¥‡à¤²à¥à¤—à¥, à¤¤à¥‡à¤²à¥à¤—à¥ ']
[38mic| self.tokenizer.batch_decode(greedy_idx, skip_special_tokens=True): [' is  s "  Rim of of the Ancient Mariner " ( " à¤•à¥la Khan ", "  well as " "   '
[38m                                                                        '" à¤•à¥Biographia Literaria ", "',
[38m                                                                        'à¤¸à¥à¤¨il Varma (  28 à¤«à¤°February 1974 )  an Indian à¤…à¤­à¤¿   pre Telugu ,   à¤¸à¥à¤¨ à¤¸à¥à¤¨ '
[38m                                                                        'à¤¸à¥à¤¨ à¤¸à¥à¤¨ à¤¸à¥à¤¨ à¤¸à¥à¤¨ à¤¸à¥à¤¨ à¤¸à¥à¤¨ à¤¸à¥à¤¨ à¤¸à¥à¤¨ à¤¸à¥à¤¨ à¤¸à¥à¤¨ à¤¸à¥à¤¨ à¤¸à¥à¤¨ à¤¸à¥à¤¨']
  0%|                                                                                                                                        | 0/33932 [00:04<?, ?it/s, model_number=0]
  0%|                                                                                                                                                    | 0/5 [00:04<?, ?it/s, loss=0]
Traceback (most recent call last):
  File "train_ddp.py", line 439, in <module>
    main()
  File "train_ddp.py", line 381, in main
    total_loss.backward()
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/_tensor.py", line 489, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 10.76 GiB total capacity; 3.04 GiB already allocated; 437.69 MiB free; 3.52 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF