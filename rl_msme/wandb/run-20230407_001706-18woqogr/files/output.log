
[38mic| model_gpus: [0]
[38mic| next(model.parameters()).is_cuda: True
[38mic| start_epoch: 0, final_checkpoint: None
  0%|                                                                                                                                                    | 0/5 [00:00<?, ?it/s, loss=0][38mic| generated_ids.shape: torch.Size([2, 3])
[38m    greedy_idx.shape: torch.Size([2, 41])[39m                                                                                                    | 0/33932 [00:00<?, ?it/s, model_number=0]
[38mic| self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True): ['<extra_id_0>', '<extra_id_0>']
[38mic| self.tokenizer.batch_decode(greedy_idx, skip_special_tokens=True): ['<extra_id_0> < <extra_id_29> <     <extra_id_51>    e: :  )     y   :  y:: ',
[38m                                                                        '<extra_id_0>.a   <become < -    <  is iscitizen actressrakash <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0>']
                                                                                                                                                                                       [38mic| generated_ids.shape: torch.Size([2, 3])
[38m    greedy_idx.shape: torch.Size([2, 40])[39m                                                                                         | 1/33932 [00:01<15:34:04,  1.65s/it, model_number=0]
[38mic| self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True): ['<extra_id_0>', '<extra_id_0>']
[38mic| self.tokenizer.batch_decode(greedy_idx, skip_special_tokens=True): ['<extra_id_0> <extra_id_31>lat-—É–ª–∞–Ω <extra_id_31> ¬ª-/>esponderEliminar '
[38m                                                                        '<extra_id_4> <extra_id_31>it <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0>',
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_4> <extra_id_55>·Éò·Éì·É† <extra_id_29>']
                                                                                                                                                                                       [38mic| generated_ids.shape: torch.Size([2, 3])
[38m    greedy_idx.shape: torch.Size([2, 53])[39m                                                                                         | 2/33932 [00:01<11:24:11,  1.21s/it, model_number=0]
[38mic| self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True): ['<extra_id_0>', '<extra_id_0>']
[38mic| self.tokenizer.batch_decode(greedy_idx, skip_special_tokens=True): ['<extra_id_0> <extra_id_0>   _)   :. <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0>',
[38m                                                                        '<extra_id_0> <extra_id_0>r√Ω—É–ª–∞–Ω Tag,-.  <extra_id_15> lusion–∫–ª—é—á–µ–ΩTÊàêÂπ¥‰∫∫']
                                                                                                                                                                                       [38mic| generated_ids.shape: torch.Size([2, 3])
[38m    greedy_idx.shape: torch.Size([2, 61])[39m                                                                                          | 3/33932 [00:01<8:26:50,  1.12it/s, model_number=0]
[38mic| self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True): ['<extra_id_0>', '<extra_id_0>']
[38mic| self.tokenizer.batch_decode(greedy_idx, skip_special_tokens=True): ['<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_30>ismiss',
[38m                                                                        '<extra_id_0>‚∏¢ <extra_id_31>jat.janak <extra_id_31>03)   <extra_id_35>  '
[38m                                                                        '<extra_id_28> <extra_id_35>‡§≤‡•ã‡§ï s‡§π‡§∞‡•Å‡§≤‡•ápaolho  ‡§Æ‡§æ‡§∏ŸÑÿßÿ¥j <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0>']
                                                                                                                                                                                       [38mic| generated_ids.shape: torch.Size([2, 3])
[38m    greedy_idx.shape: torch.Size([2, 42])[39m                                                                                          | 4/33932 [00:02<6:23:08,  1.48it/s, model_number=0]
[38mic| self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True): ['<extra_id_0>', '<extra_id_0>']
[38mic| self.tokenizer.batch_decode(greedy_idx, skip_special_tokens=True): ['<extra_id_0>  <  ‚Äòy... < <',
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_46>falls <extra_id_11>  T <extra_id_30> '
[38m                                                                        '<extra_id_16>    zƒôsto <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0>']
                                                                                                                                                                                       [38mic| generated_ids.shape: torch.Size([2, 3])
[38m    greedy_idx.shape: torch.Size([2, 44])[39m                                                                                          | 5/33932 [00:02<5:09:10,  1.83it/s, model_number=0]
[38mic| self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True): ['<extra_id_0>', '<extra_id_0>']
[38mic| self.tokenizer.batch_decode(greedy_idx, skip_special_tokens=True): ["<extra_id_0>.–ª–æ–≤–Ω–∞ k—Ç–µ–∑.e''  <extra_id_19>  <extra_id_51> (-e "
[38m                                                                        "<extra_id_15>'kenan–±–µ–∑ <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> "
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0>',
[38m                                                                        '<extra_id_0> <extra_id_31> na A,:, <extra_id_18> <extra_id_7>–∞—è '
[38m                                                                        '<extra_id_35>–∞......... <extra_id_15>2']
                                                                                                                                                                                       [38mic| generated_ids.shape: torch.Size([2, 3])
[38m    greedy_idx.shape: torch.Size([2, 48])[39m                                                                                          | 6/33932 [00:02<4:08:00,  2.28it/s, model_number=0]
[38mic| self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True): ['<extra_id_0>', '<extra_id_0>']
[38mic| self.tokenizer.batch_decode(greedy_idx, skip_special_tokens=True): ['<extra_id_0>a <extra_id_31> <extra_id_0> <extra_id_32> <extra_id_32> '
[38m                                                                        '<extra_id_32> <extra_id_31> <extra_id_31> <extra_id_31>‡§ø‡§ï‡§≤ArchivesŸÑÿßÿ¥ '
[38m                                                                        '<extra_id_31> <extra_id_31>lang <extra_id_55> <extra_id_31>rzej '
[38m                                                                        '<extra_id_31>-   <extra_id_46>laiky)gro',
[38m                                                                        '<extra_id_0>RICHp <extra_id_34>‚∏¢ <extra_id_31> <extra_id_31>| <extra_id_31> '
[38m                                                                        'nie <extra_id_31> <extra_id_31> <extra_id_31> <extra_id_31>Íªç <extra_id_31>rÍªç '
[38m                                                                        'Íªç <extra_id_31>  <extra_id_31> - <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0>']
                                                                                                                                                                                       [38mic| generated_ids.shape: torch.Size([2, 3])
[38m    greedy_idx.shape: torch.Size([2, 68])[39m                                                                                          | 7/33932 [00:02<3:25:18,  2.75it/s, model_number=0]
[38mic| self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True): ['<extra_id_0>', '<extra_id_0>']
[38mic| self.tokenizer.batch_decode(greedy_idx, skip_special_tokens=True): ['<extra_id_0>,   <extra_id_12>... <extra_id_3>tri...umim <extra_id_3>. '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0>',
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0>XzFf <extra_id_31> '
[38m                                                                        '<extra_id_31>petite—É–ª–∞–ΩÂõ∞„Çä <extra_id_31>—Ä—É–≥ <extra_id_31> <extra_id_30> '
[38m                                                                        '<extra_id_31>—Ä—É–≥ koske—Ä—É–≥—É–ª–∞–Ω <extra_id_31> <extra_id_4> <extra_id_31> '
[38m                                                                        '<extra_id_29> <extra_id_31> <extra_id_32>—Ä—É–≥rzejrzej <extra_id_29> '
[38m                                                                        '<extra_id_29> <extra_id_55> <extra_id_4> <extra_id_55> <extra_id_55> '
[38m                                                                        '<extra_id_4> <extra_id_4> <extra_id_55> <extra_id_55> <extra_id_55>Âõ∞„Çä '
[38m                                                                        '<extra_id_55> <extra_id_31> <extra_id_31> <extra_id_31> <extra_id_4>']
                                                                                                                                                                                       [38mic| generated_ids.shape: torch.Size([2, 3])
[38m    greedy_idx.shape: torch.Size([2, 39])[39m                                                                                          | 8/33932 [00:02<3:00:13,  3.14it/s, model_number=0]
[38mic| self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True): ['<extra_id_0>', '<extra_id_0>']
[38mic| self.tokenizer.batch_decode(greedy_idx, skip_special_tokens=True): ["<extra_id_0>   nicznych  Cshi..see) ),. . , q'curi eological  es.",
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_18> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> <extra_id_0> '
[38m                                                                        '<extra_id_0>']
                                                                                                                                                                                       Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9be33893b0>
Traceback (most recent call last):                                                                                                 | 9/33932 [00:03<2:38:01,  3.58it/s, model_number=0]
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1466, in __del__
    self._shutdown_workers()
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1425, in _shutdown_workers
    self._mark_worker_as_unavailable(worker_id, shutdown=True)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1373, in _mark_worker_as_unavailable
    q.put(None)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/multiprocessing/queues.py", line 82, in put
    if not self._sem.acquire(block, timeout):
KeyboardInterrupt:
  0%|                                                                                                                              | 9/33932 [00:03<3:22:25,  2.79it/s, model_number=0]
  0%|                                                                                                                                                    | 0/5 [00:03<?, ?it/s, loss=0]
Traceback (most recent call last):
  File "train_ddp.py", line 422, in <module>
    main()
  File "train_ddp.py", line 332, in main
    middle_output = model.module.middle(batch)
  File "/home2/aditya_hari/multisent/MEMS-XF2T/rl_msme/model/model_ddp.py", line 87, in middle
    max_length=self.tgt_max_seq_len
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/generation/utils.py", line 1415, in generate
    **model_kwargs,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/generation/utils.py", line 2205, in greedy_search
    output_hidden_states=output_hidden_states,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 1748, in forward
    return_dict=return_dict,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 1056, in forward
    output_attentions=output_attentions,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 563, in forward
    output_attentions=output_attentions,
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 460, in forward
    normed_hidden_states = self.layer_norm(hidden_states)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/aditya_hari/miniconda3/envs/multisent/lib/python3.7/site-packages/transformers/models/mt5/modeling_mt5.py", line 125, in forward
    variance = hidden_states.to(torch.float32).pow(2).mean(-1, keepdim=True)
KeyboardInterrupt